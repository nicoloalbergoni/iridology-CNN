Di seguito verrà fatta una descrizione generalizzata del processo di funzionamento del software, mentre nei capitoli successivi si andranno a descrivere più nel dettaglio le singole parti del codice che portano all’obiettivo finale. 

Il codice è suddiviso in tre macro-sezioni: la sezione di elaborazione delle immagini, la sezione dedicata al machine learning e infine la sezione che si occupa di effettuare le previsioni. Come prima cosa, l’utente inserisce le immagini su cui fare training nella cartella \texttt{DATA\_IMAGES}, in particolare suddivide le immagini in due subset: il set di immagini associate ad un problema andranno inserite nella sottocartella \texttt{DB\_PROBS} mentre il set di immagini che si possono definire senza problematiche va inserito nella sottocartella \texttt{DB\_NORMAL}. Una volta inseriti i dati si può procedere all’esecuzione dello script \texttt{preprocess.py}: tale script, come già anticipato, carica le immagini collocate nella cartella \texttt{DATA\_IMAGES} e successivamente richiama diverse funzioni di elaborazione delle immagini. Le immagini processate vengono poi inviate alle funzioni di riconoscimento di iride e pupilla, quelle con un riscontro positivo passano poi alla funzione di segmentazione e crop, infine si procede al resize dei segmenti ad una dimensione fissa e al salvataggio. Alla fine di questo sottoprocesso lo script crea nella cartella root del progetto una sottocartella chiamata \texttt{TEMP\_SEG},contenente a sua volta due sottocartelle chiamate \texttt{DB\_NORMAL\_SEG} e \texttt{DB\_PROBS\_SEG}. All’interno di esse troviamo rispettivamente i segmenti di iride elaborati relativi  alle immagini in \texttt{DB\_NORMAL} e in \texttt{DB\_PROBS}. E’ importante notare che nel caso di errori durante la fase di “filtraggio” delle immagini oppure nel caso di errori dovuti alla mancata rilevazione o rilevazione errata dell’iride/pupilla (intesa come rilevazione di più di un’iride/pupilla)  il programma provvede a scartare l’immagine; quindi il numero segmenti in output potrebbe risultare inferiore di quello delle immagini in input. 

Una volta generati i segmenti si procede con il training della rete neurale. Per far ciò si manda in esecuzione lo script \texttt{train.py}, che carica le immagini dei segmenti e li organizza in una struttura dati che può essere analizzata dalla rete. Una volta ottenuta tale struttura si può passare alla creazione del modello e al training vero e proprio, al termine di tale processo lo script produce in output il file \texttt{.model} che contiene tutte le informazioni relative al modello appena generato. 

\emergencystretch 5em%
Il modello può essere poi utilizzato nella fase finale, ovvero nella fase di prediction, per fare previsioni. L’utente andrà ad inserire nella cartella \texttt{DATA\_TO\_PREDICT}, sottocartella di \texttt{PREDICTION}, le immagini di cui vuole una previsione, poi inserisce nella cartella \texttt{PREDICTION} il file \texttt{.model} relativo al modello di rete neurale che si vuole utilizzare per fare la previsione. Fatta questa preparazione si esegue lo script \texttt{predict.py} che fa passare le immagini presenti nella cartella \texttt{DATA\_TO\_PREDICT} attraverso le fasi di preprocessing in modo da produrre dei segmenti utilizzabili dal modello preso in esame (in sostanza produce dei segmenti della stessa dimensione dei segmenti usati per fare il training del modello). Infine lo script carica in memoria il modello e chiede alla rete di fare previsioni sui segmenti precedentemente creati, in output l’utente si ritroverà la label (problema o normale) che la rete ha ritenuto opportuno associare a quel segmento. 

La descrizione appena fatta rappresenta un utilizzo tipico del programma, tuttavia è importante menzionare il fatto che non è obbligatorio fare un’esecuzione sequenziale delle tre macro-sezioni; infatti è possibile per esempio eseguire \texttt{predict.py} su modelli diversi e non necessariamente sull’ultimo modello creato. Di seguito si andrà a fare un descrizione dettagliata delle diverse fasi del processo, relative allo specifico caso d’uso dell’iridologia, che partendo dalle immagini di input portano alle predizioni finali. 

E’ doveroso far notare che per poter procedere nella realizzazione dell’elaborato, non avendo a disposizione immagini strettamente legate all’iridologia, si è scelto di utilizzare il dataset CASIA v.4.0, il quale è composto quasi interamente da immagini che soddisfano tutte le premesse fatte in precedenza ma che tuttavia contiene solo immagini di occhi normali (a cui non è associato nessun problema) e quindi non rappresenta un valido dataset per verificare la validità dell’iridologia. Di conseguenza i risultati di training non saranno accurati, ma per l’elaborazione delle immagini ed estrazione dei segmenti il dataset scelto si è rivelato ottimale. Per questo motivo è opportuno dire che il programma non è stato pensato e scritto solo per il caso d’uso dell’iridologia, ma è potenzialmente utilizzabile per ulteriori progetti relativi all’analisi dell’occhio, infatti si presuppone che con le adeguate immagini, categorizzate in modo opportuno, si riescano ad ottenere dei buoni risultati. 

Detto ciò, le immagini presenti in questo dataset (in seguito alla cancellazione di alcune immagini non soddisfacenti le premesse) sono 488. Si farà spesso riferimento a parametri scelti appositamente per questo caso d’uso, tarati in base alle immagini a disposizione.
